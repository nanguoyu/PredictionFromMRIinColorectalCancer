{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import nrrd\n",
    "from bs4 import BeautifulSoup\n",
    "import radiomics\n",
    "from radiomics import featureextractor  # This module is used for interaction with pyradiomics\n",
    "import six\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Fill the tumor region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fill the whole tumor region in MRI images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMask(srcpath):\n",
    "    \"\"\"\n",
    "    Find each tumor and fille the tumor by 1.\n",
    "    \"\"\"\n",
    "    imgCV = cv2.imread(srcpath)\n",
    "    img = cv2.cvtColor(imgCV, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    text1_in_image = [255, 128,64]\n",
    "    text2_in_image = [128, 128,255]\n",
    "\n",
    "    H,W,C = img.shape\n",
    "\n",
    "    mask = np.where( img[:,:,0]<60, img[:,:,1]>100, img[:,:,2]<60)\n",
    "    mask = 1* np.array(mask).astype('uint8')\n",
    "    mask_filled = np.copy(mask)\n",
    "    contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    # Todo: Check if there exists at leats one contour.\n",
    "    if len(contours)>0:\n",
    "        for contour in contours:\n",
    "            cv2.fillPoly(mask_filled,[contour],1)\n",
    "        return True, mask_filled-mask\n",
    "    else:\n",
    "#         print(\"Not found any tumor in %s\" % srcpath)\n",
    "        return False,mask_filled-mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/data/\"\n",
    "cleanedData = dataPath+\"cleanedData/\"\n",
    "orginalData = dataPath+\"orginalData/\"\n",
    "maskPath = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/mask/\"\n",
    "htmlsPath = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/DICOM files radiomics/\"\n",
    "dataNrrdPath = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/data/\"\n",
    "maskNrrdPath = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/mask/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsPaths = [v for v in glob.glob(cleanedData + \"*/\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which MRI images we would use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreDefienedMRIFolders = [\"T2U\",\"T2M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bfc073d8ed4de39396b6be9858dba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patient:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lostDataPaths = []\n",
    "notLabelledImages = []\n",
    "for i in tqdm(list(range(len(patientsPaths))), \"Patient\"):\n",
    "    pat = patientsPaths[i].split(\"\\\\\")[-2]\n",
    "    MRIsPaths = [v for v in glob.glob(patientsPaths[i] + \"*/\")]\n",
    "#     print(MRIsPaths)\n",
    "    # if exist T2M\n",
    "    T2M_Path = [v for v in MRIsPaths if v.split(\"\\\\\")[-2].find(\"T2M\")>0 and v.split(\"\\\\\")[-2].find(\"T2M+\")==-1 and v.split(\"\\\\\")[-2].find(\"frisk\")==-1  ]\n",
    "    if len(T2M_Path)<1:\n",
    "        print(\"We cannot find T2M path in \", pat)\n",
    "        continue\n",
    "        \n",
    "    T2U_Path = [v for v in MRIsPaths if v.split(\"\\\\\")[-2].find(\"T2U\")>0]\n",
    "    if len(T2U_Path)<1:\n",
    "        print(\"We cannot find T2U path in \", pat)\n",
    "        continue\n",
    "    images = [v for v in glob.glob(T2U_Path[0] + \"*.tiff\")]\n",
    "    if len(images)==0:\n",
    "        lostDataPaths.append(T2U_Path[0])\n",
    "        continue    \n",
    "\n",
    "    images = [v for v in glob.glob(T2M_Path[0] + \"*.tiff\")]\n",
    "    if len(images)==0:\n",
    "        lostDataPaths.append(T2M_Path[0])\n",
    "        continue\n",
    "#     print(T2U_Path[0].replace(dataPath,maskPath))\n",
    "\n",
    "    os.makedirs(T2U_Path[0].replace(dataPath,maskPath), exist_ok=True)\n",
    "    os.makedirs(T2M_Path[0].replace(dataPath,maskPath), exist_ok=True)\n",
    "    atLeastOneLabel = False\n",
    "    for im in images:\n",
    "        islabelled, maski = getMask(srcpath=im)\n",
    "        if not atLeastOneLabel:\n",
    "            if islabelled:\n",
    "                atLeastOneLabel = True\n",
    "#         print(T2U_Path[0].replace(dataPath,maskPath), im.replace(dataPath,maskPath))\n",
    "        cv2.imwrite(im.replace(dataPath,maskPath).replace('T2M', 'T2U'), maski)\n",
    "        cv2.imwrite(im.replace(dataPath,maskPath), maski)\n",
    "    if not atLeastOneLabel:\n",
    "        notLabelledImages.append(im.split(\"\\\\\")[-2])\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lost imgae data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/data/cleanedData\\\\Pat100\\\\Pat100T2M\\\\',\n",
       " 'C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/data/cleanedData\\\\Pat104\\\\Pat104T2U\\\\',\n",
       " 'C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/data/cleanedData\\\\Pat106\\\\Pat106T2M\\\\',\n",
       " 'C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/data/cleanedData\\\\Pat68\\\\Pat68T2M\\\\',\n",
       " 'C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/data/cleanedData\\\\Pat70\\\\Pat70T2M\\\\']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lostDataPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extract basic information from html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsHtmlPaths = [v for v in glob.glob(htmlsPath + \"*.html\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findout_id(url):\n",
    "    f = open(url,mode='r', encoding='UTF-16LE')\n",
    "    soup = BeautifulSoup(f, features=\"lxml\")\n",
    "    table = soup.find('table', class_='dataTable')\n",
    "    name = table.find(\"td\", text=\"Patients Name\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "    stage = table.find(\"td\", text=\"Tamar Scan Params\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "    slice_thickness = table.find(\"td\", text=\"Slice Thickness\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "    pixek_spacing = table.find(\"td\", text=\"Pixel Spacing\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "    spacing_between_slices = table.find(\"td\", text=\"Spacing Between Slices\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "    patients_sex = table.find(\"td\", text=\"Patients Sex\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "    patients_weight = table.find(\"td\", text=\"Patients Weight\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "#     creation_date = table.find(\"td\", text=\"Instance Creation Date\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "#     birthday = table.find(\"td\", text=\"Patients Birth Date\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").find_next_sibling(\"td\").text\n",
    "#     age = (int(creation_date)-int(birthday))/10000\n",
    "    pixek_spacing_0, pixek_spacing_1 = pixek_spacing.split(\"\\\\\")\n",
    "    patients_sex = '1' if patients_sex=='F' else '0'\n",
    "    if stage != \"T2\":\n",
    "        return \"Not T2\"\n",
    "    if name.find(\"-\")>-1:\n",
    "        return [name.split(\"_\")[-1], spacing_between_slices, pixek_spacing_0, pixek_spacing_1, slice_thickness, patients_sex, patients_weight]\n",
    "    else:\n",
    "        a = list(name.split(\"_\")[-1])\n",
    "        return [''.join(a[:-1]+['-']+[a[-1]]), spacing_between_slices, pixek_spacing_0, pixek_spacing_1, slice_thickness, patients_sex, patients_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = {}\n",
    "for p in patientsHtmlPaths:\n",
    "    pat = p.split(\"\\\\\")[-1].split(\"_\")[0][3:].strip()\n",
    "    html_result = findout_id(p)\n",
    "    if html_result==\"Not T2\":\n",
    "        continue\n",
    "    patient_id[html_result[0]] = [pat]+html_result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally  61 patients with DICOM HTML files\n"
     ]
    }
   ],
   "source": [
    "print(\"There are totally \", len(patient_id), \"patients with DICOM HTML files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomePath2 = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/Outcome data radiomics/Radiomics_outcome_deidentified.xlsx\"\n",
    "df2 = pd.read_excel(outcomePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_outcome = {}\n",
    "res3 = []\n",
    "for k,v in patient_id.items():\n",
    "#     print(v)\n",
    "    out = df2.loc[df2.Column1==k].iloc[:, [-1]].values\n",
    "    if out is not None:\n",
    "        if len(out)>1: \n",
    "#             print(k,v, out[0][0])\n",
    "            if out[0][0].strip()==\"Not assessable\":\n",
    "                continue\n",
    "            patient_outcome[v[0].strip()] = [v[1],v[2],v[3], v[4], v[5], v[6], out[0][0].strip()]\n",
    "#             res3.append([int(v[0].strip()), out[0][0].strip()])\n",
    "        elif len(out)==1:\n",
    "#             print(k,v, out[0][0])\n",
    "            if out[0][0].strip()==\"Not assessable\":\n",
    "                continue\n",
    "            patient_outcome[v[0].strip()] = [v[1],v[2],v[3], v[4], v[5], v[6], out[0][0].strip()]\n",
    "#             res3.append([int(v[0].strip()), out[0][0].strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of patients having T2U and T2M MRI images AND having outcome: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of patients having T2U and T2M MRI images AND having outcome:\", len(patient_outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save result to patient_outcome.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"Save result to patient_outcome.npy\")\n",
    "np.save(\"./patient_outcome.npy\", patient_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Convert .tiff image to 3D .nrrd image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_T2_info = np.load(\"./patient_outcome.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainMetaDataFromDICOM(id_):\n",
    "    r = output_T2_info.get(str(id_))\n",
    "    if not r:\n",
    "        return None\n",
    "    return list(map(float, r[0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImageeNrrd(sourcePath, targetPath, id_):\n",
    "    images = [v for v in glob.glob(sourcePath + \"*.tiff\")]\n",
    "#     print(len(images))\n",
    "    if len(images)>0:\n",
    "        targetFileName = targetPath + targetPath.split(\"\\\\\")[-2]+\".nrrd\"\n",
    "        s = np.unique( list(map(len,  list(map(lambda path: cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2GRAY),sorted(images)  )))) )\n",
    "        if len(s)>1:\n",
    "            raise ValueError(\"Wrong image shape\", sourcePath)\n",
    "        imgs = np.stack( list(map(lambda path: cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2GRAY),sorted(images))) )\n",
    "#         out = sitk.GetImageFromArray(imgs)\n",
    "        \n",
    "        MetaData = obtainMetaDataFromDICOM(id_)\n",
    "        if MetaData:\n",
    "#             out.SetSpacing(space)\n",
    "#             sitk.WriteImage(out, targetFileName)\n",
    "            header = {'spacings':MetaData[0:3],'thicknesses': [float('nan'),float('nan'),MetaData[-1]]}\n",
    "            nrrd.write(targetFileName, imgs,header,index_order='C')\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate NRRD file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9feb62d2b07d4415bbc22b7265b6821c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patient:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "lostDataPaths = []\n",
    "c=0\n",
    "for i in tqdm(list(range(len(patientsPaths))), \"Patient\"):\n",
    "    pat = patientsPaths[i].split(\"\\\\\")[-2]\n",
    "#     print(pat)\n",
    "    MRIsPaths = [v for v in glob.glob(patientsPaths[i] + \"*/\")]\n",
    "#     print(MRIsPaths)\n",
    "    # if exist T2M\n",
    "    T2M_Path = [v for v in MRIsPaths if v.split(\"\\\\\")[-2].find(\"T2M\")>0 and v.split(\"\\\\\")[-2].find(\"T2M+\")==-1 and v.split(\"\\\\\")[-2].find(\"frisk\")==-1  ]\n",
    "    if len(T2M_Path)<1:\n",
    "        print(\"We cannot find T2M path in \", pat)\n",
    "        continue\n",
    "        \n",
    "    T2U_Path = [v for v in MRIsPaths if v.split(\"\\\\\")[-2].find(\"T2U\")>0]\n",
    "    if len(T2U_Path)<1:\n",
    "        print(\"We cannot find T2U path in \", pat)\n",
    "        continue\n",
    "    images = [v for v in glob.glob(T2U_Path[0] + \"*.tiff\")]\n",
    "    if len(images)==0:\n",
    "        lostDataPaths.append(T2U_Path[0])\n",
    "        continue    \n",
    "\n",
    "    images = [v for v in glob.glob(T2M_Path[0] + \"*.tiff\")]\n",
    "    if len(images)==0:\n",
    "        lostDataPaths.append(T2M_Path[0])\n",
    "        continue\n",
    "    # T2U image nrrd\n",
    "\n",
    "    src,tar = T2U_Path[0], T2U_Path[0].replace(dataPath,dataNrrdPath)\n",
    "    os.makedirs(tar, exist_ok=True)\n",
    "    flag = convertImageeNrrd(src,tar, int(pat[3:]))\n",
    "    # T2M image nrrd\n",
    "    if not flag:\n",
    "        continue\n",
    "        \n",
    "    src,tar = T2M_Path[0], T2M_Path[0].replace(dataPath,dataNrrdPath)\n",
    "    os.makedirs(tar, exist_ok=True)\n",
    "    flag = convertImageeNrrd(src,tar,int(pat[3:]))\n",
    "    if not flag:\n",
    "        continue\n",
    "    # T2M mask nrrd\n",
    "\n",
    "    src,tar = T2M_Path[0].replace(dataPath,maskPath), T2M_Path[0].replace(dataPath,maskNrrdPath)\n",
    "    os.makedirs(tar, exist_ok=True)\n",
    "    flag = convertImageeNrrd(src,tar, int(pat[3:]))\n",
    "    # T2U mask nrrd\n",
    "    if not flag:\n",
    "        continue\n",
    "#     src,tar = T2U_Path[0].replace(dataPath,maskPath), T2U_Path[0].replace(dataPath,maskNrrdPath)\n",
    "#     os.makedirs(tar, exist_ok=True)\n",
    "#     flag = convertImageeNrrd(src,tar, int(pat[3:]))\n",
    "    c = c+1\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lostDataPaths = np.array(['Pat100','Pat106','Pat68','Pat104','Pat70','Pat105'], dtype='<U33')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramPath = os.path.join('Params_customization.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction parameters:\n",
      "\t {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True, 'binWidth': 25, 'weightingNorm': None}\n",
      "Enabled filters:\n",
      "\t {'Original': {}, 'LoG': {'sigma': [1.0, 1.5, 2.0, 2.5, 3.0]}}\n",
      "Enabled features:\n",
      "\t {'shape': None, 'firstorder': None, 'glcm': ['Autocorrelation', 'JointAverage', 'ClusterProminence', 'ClusterShade', 'ClusterTendency', 'Contrast', 'Correlation', 'DifferenceAverage', 'DifferenceEntropy', 'DifferenceVariance', 'JointEnergy', 'JointEntropy', 'Imc1', 'Imc2', 'Idm', 'Idmn', 'Id', 'Idn', 'InverseVariance', 'MaximumProbability', 'SumEntropy', 'SumSquares']}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(paramPath)\n",
    "\n",
    "print('Extraction parameters:\\n\\t', extractor.settings)\n",
    "print('Enabled filters:\\n\\t', extractor.enabledImagetypes)\n",
    "print('Enabled features:\\n\\t', extractor.enabledFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNrrdPath = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/data/cleanedData\\\\\"\n",
    "maskNrrdPath = \"C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/mask/cleanedData\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsPaths = [v for v in glob.glob(cleanedData + \"*/\")]\n",
    "patientMaskPaths  = [v for v in glob.glob(maskNrrdPath + \"*/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adda695db7bb40788fff41dc07ef2606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patient mask:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat1/Pat1.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat102/Pat102.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat103/Pat103.pickle\n",
      "Lost patient: Pat105\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat11/Pat11.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat12/Pat12.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat13/Pat13.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat14/Pat14.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat16/Pat16.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat18/Pat18.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat19/Pat19.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat2/Pat2.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat20/Pat20.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat21/Pat21.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat24/Pat24.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat30/Pat30.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat31/Pat31.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat38/Pat38.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat39/Pat39.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat4/Pat4.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat40/Pat40.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat42/Pat42.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat44/Pat44.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat46/Pat46.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat47/Pat47.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat49/Pat49.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat51/Pat51.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat54/Pat54.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat55/Pat55.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat56/Pat56.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat58/Pat58.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat59/Pat59.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat6/Pat6.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat61/Pat61.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat66/Pat66.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat67/Pat67.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat69/Pat69.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat73/Pat73.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat8/Pat8.pickle\n",
      "process result in  C:/Users/nangu/OneDrive - Uppsala universitet/ComputationalScienceProjectData/nrrd/result/cleanedData/Pat9/Pat9.pickle\n"
     ]
    }
   ],
   "source": [
    "resultFilePaths = []\n",
    "for i in tqdm(list(range(len(patientMaskPaths))), \"Patient mask\"):\n",
    "    pat = patientMaskPaths[i].split(\"\\\\\")[-2]\n",
    "    if pat in lostDataPaths:\n",
    "        print(\"Lost patient:\", pat)\n",
    "        continue\n",
    "#     print(patientMaskPaths[i].replace(maskNrrdPath,dataNrrdPath))\n",
    "    MRIsDataPaths = [v for v in glob.glob(patientMaskPaths[i].replace(maskNrrdPath,dataNrrdPath) + \"*\\\\*.nrrd\")]\n",
    "    MRIsMaskPaths = [v for v in glob.glob(patientMaskPaths[i] + \"*\\\\*.nrrd\")]\n",
    "    T2M_Path = [v for v in MRIsMaskPaths if v.split(\"\\\\\")[-2].find(\"T2M\")>0 and v.split(\"\\\\\")[-2].find(\"T2M+\")==-1 and v.split(\"\\\\\")[-2].find(\"frisk\")==-1  ]\n",
    "    if len(T2M_Path)<1:\n",
    "        print(\"We cannot find T2M path in \", pat)\n",
    "        continue\n",
    "#     print(T2M_Path)\n",
    "        \n",
    "    T2U_Path = [v for v in MRIsDataPaths if v.split(\"\\\\\")[-2].find(\"T2U\")>0]\n",
    "    if len(T2U_Path)<1:\n",
    "        print(\"We cannot find T2U path in \", pat)\n",
    "        continue\n",
    "#     print(T2U_Path)\n",
    "    image_folder_path = '/'.join(T2U_Path[0].split(\"\\\\\")[0:2])+'/'\n",
    "    image_path = T2U_Path[0]\n",
    "\n",
    "    \n",
    "#     mask_folder_path = T2M_Path[0]\n",
    "#     mask_path = mask_folder_path+mask_folder_path.split(\"\\\\\")[-2]+\".nrrd\"    \n",
    "    mask_path = T2M_Path[0]\n",
    "    result_path = image_folder_path.replace(\"data\", \"result\")\n",
    "    resultFilePath = result_path +image_folder_path.split(\"/\")[-2]+\".pickle\"\n",
    "#     print(image_path)\n",
    "#     print(mask_path)\n",
    "    result = extractor.execute(image_path, mask_path)\n",
    "    os.makedirs(result_path, exist_ok=True)            \n",
    "    pickle.dump(result, open(resultFilePath, 'wb'))\n",
    "    print(\"process result in \", resultFilePath)\n",
    "    resultFilePaths.append(resultFilePath)\n",
    "\n",
    "np.save(\"./resultFilePaths.npy\", np.array(resultFilePaths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
